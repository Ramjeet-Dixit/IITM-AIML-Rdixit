{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramjeet-Dixit/IITM-AIML-Rdixit/blob/main/Keras_Tuner_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JelbhOM9dufb",
        "outputId": "e871cdfc-08b3-46ed-fccf-957ff756a6fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbZIeWaDcj-L",
        "outputId": "96e88b3c-d42f-464e-e8a5-a09d0f38e403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2543834074.py:7: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner.tuners import RandomSearch #randomsearch instead of hyperband\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.utils import to_categorical #np_utils updated to to_categorical\n",
        "from kerastuner.tuners import RandomSearch #randomsearch instead of hyperband\n",
        "\n",
        "# Load dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize the images to a 0 to 1 range\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D6zdnqAd8Vm"
      },
      "source": [
        "In a CNN, convolutional layer accepts images in 3 dimension\n",
        "\n",
        "fashion mnist data, 2D, width x height\n",
        "\n",
        "add a third dimension, depth (color channel)\n",
        "\n",
        "from 28x28 to 28x28x1..60000, 28,28,1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvhaaQpSeiAV",
        "outputId": "f774cbf0-0b68-4933-c2d4-e8523d57be96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbrbyYpYdM-E"
      },
      "outputs": [],
      "source": [
        "# Reshape dataset to have a single channel\n",
        "#x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
        "#x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tP9lBSHeu01",
        "outputId": "5dee9697-d617-4534-c6e6-4aff7de24b93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNCb4--pexvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3563281b-45d5-4f55-847d-bcf2dd42f927"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       ...,\n",
              "       [9],\n",
              "       [1],\n",
              "       [1]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhMfCSsifg8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35d74e0e-9f24-4d5c-d0f5-bdc4a898b29c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "len(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDj0OQW_gLyv"
      },
      "source": [
        "For instance, if there are 10 classes, the class label 2 would be represented as [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzdGOnWPf_ua"
      },
      "outputs": [],
      "source": [
        "# Convert class vectors to binary class matrices\n",
        "#required only if categorcial crossentropy method is used, not with sparse method\n",
        "y_train = to_categorical(y_train, 10) #60000 labels\n",
        "y_test = to_categorical(y_test, 10) #10000 labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XmrZZHwgxI6",
        "outputId": "5835a0fe-4880-4afa-a282-1a7b67e30cc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import BatchNormalization"
      ],
      "metadata": {
        "id": "R_riEaaBYTC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "I8n3EPn7IomO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "batchnormalisation\n",
        "\n",
        "it works by rescaling the outputs of a layers so they stay in a healthy range (0 to 1) instead of becoming too large or too small\n",
        "\n",
        "keeps the layer's output nicelty centred and scaled\n",
        "\n",
        "adjusting exam scores of every class has mean 0 and stdev 1 before fuurther grading\n",
        "\n",
        "Step 1: Compute batch statistics\n",
        "\n",
        "For current batch:\n",
        "\n",
        "calculates the mean: batch mean\n",
        "\n",
        "calculates the variance: batch variance\n",
        "\n",
        "Step 2: Normalization\n",
        "\n",
        "x_normalised = (x -  mean) /stdev\n",
        "\n",
        "now the values, mean 0 and stdev 1\n",
        "\n",
        "Step 3: Learnable scale + shift\n",
        "\n",
        "Batch norm adds two trainable parameters\n",
        "\n",
        "1. gamma - scale\n",
        "\n",
        "2. beta - shift\n",
        "\n",
        "output = gamma * x_normalised + beta --  Why?\n",
        "\n",
        "because may be mean 0 and stdev 1 might not be ideal..the network can learn the best scale and offset accordingly\n",
        "\n",
        "During inference (testing)\n",
        "\n",
        "at the testing, no batch to compute mean and variance\n",
        "\n",
        "so batchnorm uses:\n",
        "\n",
        "1. running average of mean\n",
        "\n",
        "2. running average of variance\n",
        "\n",
        "Momemtum: Memory of the past\n",
        "\n",
        "keeps a running estimate of the mean and the variance\n",
        "\n",
        "which are later used for testing.\n",
        "\n",
        "Momemtum decides how fast these running estimate  values update\n",
        "\n",
        "how much trust past batches vs the current batch\n",
        "\n",
        "example: momemtum 0.9\n",
        "\n",
        "new_running_mean = 0.9 * old_running_mean + 0.1 x current_batch_mean"
      ],
      "metadata": {
        "id": "LXTecYhTetnk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_4xKHjfgyg7"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential() #instantiate the sequential method\n",
        "    model.add(Conv2D(filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n",
        "                     kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),\n",
        "                     activation='relu',\n",
        "                     input_shape=(32,32,3)))\n",
        "    # Add batch normalization with tunable momentum and epsilon\n",
        "    model.add(BatchNormalization(\n",
        "        momentum=hp.Float('bn_momentum', min_value=0.8, max_value=0.99, step=0.05),\n",
        "        epsilon=hp.Float('bn_epsilon', min_value=1e-5, max_value=1e-3, step=1e-5)\n",
        "    ))\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),\n",
        "                     kernel_size=hp.Choice('conv_2_kernel', values = [3,5]),\n",
        "                     activation='relu'))\n",
        "    model.add(BatchNormalization(\n",
        "        momentum=hp.Float('bn_momentum_2', min_value=0.8, max_value=0.99, step=0.05),\n",
        "        epsilon=hp.Float('bn_epsilon_2', min_value=1e-5, max_value=1e-3, step=1e-5)\n",
        "    ))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#ANN\n",
        "    model.add(Flatten()) #input layer\n",
        "    model.add(Dense(units=hp.Int('dense_units', min_value=32, max_value=128, step=32),\n",
        "                    activation='relu')) #hidden layers\n",
        "    model.add(Dropout(rate=hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "    model.add(Dense(10, activation='softmax')) #output layer\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZ1af3PRZxYB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5b8d4ea-2eb3-458e-b46d-0c201e3b9e7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Setup Keras Tuner\n",
        "tuner = RandomSearch(build_model,\n",
        "                     objective='val_accuracy',\n",
        "                     max_trials=5,\n",
        "                     executions_per_trial=3,\n",
        "                     directory='output',\n",
        "                     project_name='FashionMNIST',\n",
        "                     overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#early stopping to overcome the overfitting\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ],
      "metadata": {
        "id": "j7VLF3quQfv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(x_train, y_train, epochs=10, validation_split=0.2, callbacks=[stop_early])"
      ],
      "metadata": {
        "id": "ci-o5oNsQoe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cffceb3-429f-4fac-df4c-daf9c052900a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 03m 29s]\n",
            "val_accuracy: 0.6432333191235861\n",
            "\n",
            "Best val_accuracy So Far: 0.7048999865849813\n",
            "Total elapsed time: 00h 16m 47s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "#number of units in the hidden layer\n",
        "#learning rate\n",
        "\n",
        "#num_trials: Optional number of HyperParameters objects to return.\n",
        "\n",
        "#Returns\n",
        "#List of HyperParameter objects sorted from the best to the worst."
      ],
      "metadata": {
        "id": "uwYzCxNyZoFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(best_hps.get('conv_1_filter'))\n",
        "print(best_hps.get('conv_1_kernel'))\n",
        "print(best_hps.get('conv_2_filter'))\n",
        "print(best_hps.get('conv_2_kernel'))\n",
        "print(best_hps.get('dense_units'))\n",
        "print(best_hps.get('learning_rate'))\n",
        "print(best_hps.get('dropout_rate'))"
      ],
      "metadata": {
        "id": "0LlNFme5i2TT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c208eb9-6d49-4e07-9cf8-37b74fa955ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96\n",
            "3\n",
            "48\n",
            "5\n",
            "96\n",
            "0.001\n",
            "0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "newmodel = model.fit(x_train, y_train, epochs=50, validation_split=0.2)\n",
        "newmodel"
      ],
      "metadata": {
        "id": "8jBivT55jrFC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1900af99-ee21-4c4f-eedf-ac3463f82dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.3967 - loss: 1.7447 - val_accuracy: 0.5262 - val_loss: 1.3067\n",
            "Epoch 2/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5810 - loss: 1.1831 - val_accuracy: 0.5177 - val_loss: 1.3652\n",
            "Epoch 3/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6569 - loss: 0.9840 - val_accuracy: 0.6383 - val_loss: 1.0469\n",
            "Epoch 4/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6970 - loss: 0.8678 - val_accuracy: 0.6526 - val_loss: 1.0568\n",
            "Epoch 5/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.7220 - loss: 0.7812 - val_accuracy: 0.6865 - val_loss: 0.9232\n",
            "Epoch 6/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7496 - loss: 0.7051 - val_accuracy: 0.6576 - val_loss: 1.0001\n",
            "Epoch 7/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7792 - loss: 0.6284 - val_accuracy: 0.7180 - val_loss: 0.8380\n",
            "Epoch 8/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.5820 - val_accuracy: 0.7041 - val_loss: 0.9038\n",
            "Epoch 9/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8120 - loss: 0.5282 - val_accuracy: 0.7156 - val_loss: 0.8670\n",
            "Epoch 10/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8229 - loss: 0.4935 - val_accuracy: 0.6597 - val_loss: 1.1051\n",
            "Epoch 11/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8390 - loss: 0.4552 - val_accuracy: 0.6883 - val_loss: 1.0926\n",
            "Epoch 12/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8537 - loss: 0.4109 - val_accuracy: 0.6965 - val_loss: 1.0113\n",
            "Epoch 13/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8588 - loss: 0.3920 - val_accuracy: 0.6823 - val_loss: 1.1407\n",
            "Epoch 14/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8703 - loss: 0.3665 - val_accuracy: 0.7056 - val_loss: 1.0806\n",
            "Epoch 15/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8752 - loss: 0.3468 - val_accuracy: 0.7146 - val_loss: 1.0463\n",
            "Epoch 16/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8791 - loss: 0.3301 - val_accuracy: 0.7097 - val_loss: 1.0662\n",
            "Epoch 17/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8922 - loss: 0.2989 - val_accuracy: 0.6986 - val_loss: 1.1202\n",
            "Epoch 18/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8931 - loss: 0.2945 - val_accuracy: 0.6886 - val_loss: 1.2956\n",
            "Epoch 19/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8979 - loss: 0.2825 - val_accuracy: 0.7088 - val_loss: 1.1326\n",
            "Epoch 20/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9029 - loss: 0.2684 - val_accuracy: 0.7098 - val_loss: 1.2431\n",
            "Epoch 21/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9140 - loss: 0.2446 - val_accuracy: 0.7191 - val_loss: 1.2362\n",
            "Epoch 22/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9091 - loss: 0.2521 - val_accuracy: 0.7151 - val_loss: 1.1890\n",
            "Epoch 23/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9144 - loss: 0.2382 - val_accuracy: 0.6975 - val_loss: 1.3977\n",
            "Epoch 24/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9159 - loss: 0.2375 - val_accuracy: 0.7098 - val_loss: 1.2404\n",
            "Epoch 25/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9191 - loss: 0.2272 - val_accuracy: 0.7085 - val_loss: 1.2229\n",
            "Epoch 26/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9199 - loss: 0.2240 - val_accuracy: 0.7102 - val_loss: 1.3065\n",
            "Epoch 27/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9208 - loss: 0.2198 - val_accuracy: 0.7054 - val_loss: 1.3718\n",
            "Epoch 28/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9252 - loss: 0.2062 - val_accuracy: 0.6953 - val_loss: 1.3613\n",
            "Epoch 29/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9253 - loss: 0.2099 - val_accuracy: 0.7088 - val_loss: 1.4509\n",
            "Epoch 30/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9281 - loss: 0.1998 - val_accuracy: 0.6920 - val_loss: 1.5167\n",
            "Epoch 31/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9356 - loss: 0.1860 - val_accuracy: 0.7051 - val_loss: 1.4909\n",
            "Epoch 32/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9335 - loss: 0.1906 - val_accuracy: 0.7079 - val_loss: 1.4367\n",
            "Epoch 33/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9370 - loss: 0.1790 - val_accuracy: 0.7172 - val_loss: 1.3888\n",
            "Epoch 34/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9377 - loss: 0.1745 - val_accuracy: 0.7107 - val_loss: 1.5625\n",
            "Epoch 35/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9363 - loss: 0.1794 - val_accuracy: 0.7029 - val_loss: 1.5411\n",
            "Epoch 36/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9378 - loss: 0.1732 - val_accuracy: 0.7021 - val_loss: 1.5399\n",
            "Epoch 37/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9422 - loss: 0.1628 - val_accuracy: 0.7120 - val_loss: 1.5193\n",
            "Epoch 38/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9405 - loss: 0.1684 - val_accuracy: 0.7123 - val_loss: 1.5297\n",
            "Epoch 39/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9447 - loss: 0.1590 - val_accuracy: 0.7108 - val_loss: 1.5522\n",
            "Epoch 40/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9406 - loss: 0.1684 - val_accuracy: 0.6973 - val_loss: 1.6608\n",
            "Epoch 41/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9422 - loss: 0.1654 - val_accuracy: 0.7100 - val_loss: 1.6018\n",
            "Epoch 42/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9463 - loss: 0.1505 - val_accuracy: 0.7086 - val_loss: 1.5825\n",
            "Epoch 43/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9475 - loss: 0.1520 - val_accuracy: 0.7172 - val_loss: 1.6351\n",
            "Epoch 44/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9465 - loss: 0.1508 - val_accuracy: 0.7062 - val_loss: 1.5651\n",
            "Epoch 45/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9479 - loss: 0.1507 - val_accuracy: 0.7070 - val_loss: 1.5717\n",
            "Epoch 46/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9471 - loss: 0.1487 - val_accuracy: 0.7065 - val_loss: 1.6583\n",
            "Epoch 47/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9492 - loss: 0.1508 - val_accuracy: 0.7019 - val_loss: 1.6111\n",
            "Epoch 48/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9520 - loss: 0.1415 - val_accuracy: 0.7054 - val_loss: 1.6696\n",
            "Epoch 49/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9484 - loss: 0.1475 - val_accuracy: 0.7124 - val_loss: 1.6371\n",
            "Epoch 50/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9521 - loss: 0.1397 - val_accuracy: 0.6983 - val_loss: 1.8192\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d526a452660>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "val_acc_per_epoch = newmodel.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "metadata": {
        "id": "PWSmbMT3P21v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eecbf1a7-2268-4f03-a1da-2ae1af30d0f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best epoch: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(x_train, y_train, epochs=best_epoch, validation_split=0.2)"
      ],
      "metadata": {
        "id": "E9bIufLgnA8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b246e74c-cdf0-4490-cc43-600077a0e71b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.4001 - loss: 1.7265 - val_accuracy: 0.4937 - val_loss: 1.3949\n",
            "Epoch 2/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5906 - loss: 1.1652 - val_accuracy: 0.6031 - val_loss: 1.1039\n",
            "Epoch 3/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6519 - loss: 0.9906 - val_accuracy: 0.6500 - val_loss: 1.0047\n",
            "Epoch 4/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6943 - loss: 0.8724 - val_accuracy: 0.6052 - val_loss: 1.1625\n",
            "Epoch 5/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7301 - loss: 0.7724 - val_accuracy: 0.6554 - val_loss: 0.9778\n",
            "Epoch 6/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7485 - loss: 0.7060 - val_accuracy: 0.6258 - val_loss: 1.0843\n",
            "Epoch 7/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7716 - loss: 0.6456 - val_accuracy: 0.6977 - val_loss: 0.9689\n",
            "Epoch 8/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7941 - loss: 0.5835 - val_accuracy: 0.7188 - val_loss: 0.8568\n",
            "Epoch 9/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8122 - loss: 0.5230 - val_accuracy: 0.6566 - val_loss: 1.0932\n",
            "Epoch 10/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8208 - loss: 0.5014 - val_accuracy: 0.6932 - val_loss: 1.0509\n",
            "Epoch 11/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8349 - loss: 0.4623 - val_accuracy: 0.7106 - val_loss: 0.9313\n",
            "Epoch 12/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8453 - loss: 0.4288 - val_accuracy: 0.7035 - val_loss: 0.9757\n",
            "Epoch 13/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8569 - loss: 0.3962 - val_accuracy: 0.6936 - val_loss: 1.0717\n",
            "Epoch 14/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8668 - loss: 0.3759 - val_accuracy: 0.7154 - val_loss: 0.9823\n",
            "Epoch 15/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8714 - loss: 0.3523 - val_accuracy: 0.7042 - val_loss: 1.0563\n",
            "Epoch 16/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8860 - loss: 0.3186 - val_accuracy: 0.6944 - val_loss: 1.2688\n",
            "Epoch 17/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8849 - loss: 0.3112 - val_accuracy: 0.7099 - val_loss: 1.1380\n",
            "Epoch 18/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8926 - loss: 0.2943 - val_accuracy: 0.6971 - val_loss: 1.2549\n",
            "Epoch 19/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8967 - loss: 0.2907 - val_accuracy: 0.7192 - val_loss: 1.1765\n",
            "Epoch 20/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9049 - loss: 0.2663 - val_accuracy: 0.6942 - val_loss: 1.2590\n",
            "Epoch 21/21\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9064 - loss: 0.2624 - val_accuracy: 0.7073 - val_loss: 1.1988\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d528890f980>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = hypermodel.evaluate(x_test, y_test)\n",
        "print(\"[test loss, test accuracy]:\", eval_result)"
      ],
      "metadata": {
        "id": "YmAQ8fXwoCvo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34e6dc91-de8b-41d6-ec53-4a097aa90190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6957 - loss: 1.1930\n",
            "[test loss, test accuracy]: [1.2085222005844116, 0.6969000101089478]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = hypermodel.evaluate(x_train, y_train)\n",
        "print(\"[train loss, train accuracy]:\", eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OksU5QG-x0e5",
        "outputId": "7858c5fc-af82-409c-e284-018e4c6a78c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9468 - loss: 0.1718\n",
            "[train loss, train accuracy]: [0.35883063077926636, 0.902679979801178]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvkjK-2cioIj"
      },
      "source": [
        "# Setup Hyperband tuner\n",
        "tuner = Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    directory='output',\n",
        "    project_name='FashionMNIST_Hyperband',\n",
        "    overwrite=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0110QBpi2A_"
      },
      "source": [
        "#early stopping to overcome the overfitting\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "F-U3ZOTDal2H"
      },
      "outputs": [],
      "source": [
        "#skipping on early stopping for this example\n",
        "tuner.search(x_train, y_train, epochs=10, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "752uaenta-On"
      },
      "outputs": [],
      "source": [
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "#skipped the tuning of no of epochs\n",
        "newmodel = model.fit(x_train, y_train, epochs=50, validation_split=0.2)\n",
        "\n",
        "val_acc_per_epoch = newmodel.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOcghdWriNE6"
      },
      "outputs": [],
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(x_train, y_train, epochs=best_epoch, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKRxCtyWiF_C"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Evaluate the best model\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_accuracy}, Test loss: {test_loss}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}