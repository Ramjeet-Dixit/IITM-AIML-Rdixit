{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramjeet-Dixit/IITM-AIML-Rdixit/blob/main/Spam_detection_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cZBptYROjE5T",
        "outputId": "230ff8ad-ecf7-43f3-8371-e467b4b99a64"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/ramjeetdixit/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#import required libraries\n",
        "import pandas as pd\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "id": "P0jihT_djE5W"
      },
      "outputs": [],
      "source": [
        "#get the sentiment dataset\n",
        "df_spam = pd.read_csv(\"/Users/ramjeetdixit/Downloads/SpamCollection\",sep='\\t',names=['comment','label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kR3Mif2mjE5X"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  comment                                              label\n",
              "0     ham  Go until jurong point, crazy.. Available only ...\n",
              "1     ham                      Ok lar... Joking wif u oni...\n",
              "2    spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3     ham  U dun say so early hor... U c already then say...\n",
              "4     ham  Nah I don't think he goes to usf, he lives aro...\n",
              "5    spam  FreeMsg Hey there darling it's been 3 week's n...\n",
              "6     ham  Even my brother is not like to speak with me. ...\n",
              "7     ham  As per your request 'Melle Melle (Oru Minnamin...\n",
              "8    spam  WINNER!! As a valued network customer you have...\n",
              "9    spam  Had your mobile 11 months or more? U R entitle..."
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#view first 10 observations.\n",
        "# 1 indicates positive sentiment and 0 indicate negative sentiment\n",
        "df_spam.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5ikQ-3pIjE5Y"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  comment                                              label\n",
              "0     ham  Go until jurong point, crazy.. Available only ...\n",
              "1     ham                      Ok lar... Joking wif u oni...\n",
              "2    spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3     ham  U dun say so early hor... U c already then say...\n",
              "4     ham  Nah I don't think he goes to usf, he lives aro...\n",
              "5    spam  FreeMsg Hey there darling it's been 3 week's n...\n",
              "6     ham  Even my brother is not like to speak with me. ...\n",
              "7     ham  As per your request 'Melle Melle (Oru Minnamin...\n",
              "8    spam  WINNER!! As a valued network customer you have...\n",
              "9    spam  Had your mobile 11 months or more? U R entitle..."
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#view more info on data\n",
        "df_spam.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OPgREnCWjE5Z"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"4\" halign=\"left\">label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comment</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>&amp;lt;#&amp;gt;  in mca. But not conform.</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>&amp;lt;#&amp;gt;  mins but i had to stop somewhere first.</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>&amp;lt;DECIMAL&amp;gt; m but its not a common car here so its better to buy from china or asia. Or if i find it less expensive. I.ll holla</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>and  picking them up from various points</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>came to look at the flat, seems ok, in his 50s? * Is away alot wiv work. Got woman coming at 6.30 too.</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ü thk of wat to eat tonight.</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ü v ma fan...</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ü wait 4 me in sch i finish ard 5..</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>… and don‘t worry we‘ll have finished by march … ish!</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>… we r stayin here an extra week, back next wed. How did we do in the rugby this weekend? Hi to and and , c u soon \"</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5169 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   label                 \n",
              "                                                   count unique  top freq\n",
              "comment                                                                  \n",
              " &lt;#&gt;  in mca. But not conform.                   1      1  ham    1\n",
              " &lt;#&gt;  mins but i had to stop somewhere fi...     1      1  ham    1\n",
              " &lt;DECIMAL&gt; m but its not a common car her...     1      1  ham    1\n",
              " and  picking them up from various points              1      1  ham    1\n",
              " came to look at the flat, seems ok, in his 50s...     1      1  ham    1\n",
              "...                                                  ...    ...  ...  ...\n",
              "Ü thk of wat to eat tonight.                           1      1  ham    1\n",
              "Ü v ma fan...                                          1      1  ham    1\n",
              "Ü wait 4 me in sch i finish ard 5..                    1      1  ham    1\n",
              "… and don‘t worry we‘ll have finished by march ...     1      1  ham    1\n",
              "… we r stayin here an extra week, back next wed...     1      1  ham    1\n",
              "\n",
              "[5169 rows x 4 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# view data using group by and describe method\n",
        "df_spam.groupby('comment').describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6VWJkkyC3NY5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"4\" halign=\"left\">comment</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>&amp;lt;#&amp;gt;  in mca. But not conform.</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>&amp;lt;#&amp;gt;  mins but i had to stop somewhere first.</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>&amp;lt;DECIMAL&amp;gt; m but its not a common car here so its better to buy from china or asia. Or if i find it less expensive. I.ll holla</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>and  picking them up from various points</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>came to look at the flat, seems ok, in his 50s? * Is away alot wiv work. Got woman coming at 6.30 too.</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ü thk of wat to eat tonight.</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ü v ma fan...</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ü wait 4 me in sch i finish ard 5..</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>… and don‘t worry we‘ll have finished by march … ish!</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>… we r stayin here an extra week, back next wed. How did we do in the rugby this weekend? Hi to and and , c u soon \"</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5169 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   comment                 \n",
              "                                                     count unique  top freq\n",
              "label                                                                      \n",
              " &lt;#&gt;  in mca. But not conform.                     1      1  ham    1\n",
              " &lt;#&gt;  mins but i had to stop somewhere fi...       1      1  ham    1\n",
              " &lt;DECIMAL&gt; m but its not a common car her...       1      1  ham    1\n",
              " and  picking them up from various points                1      1  ham    1\n",
              " came to look at the flat, seems ok, in his 50s...       1      1  ham    1\n",
              "...                                                    ...    ...  ...  ...\n",
              "Ü thk of wat to eat tonight.                             1      1  ham    1\n",
              "Ü v ma fan...                                            1      1  ham    1\n",
              "Ü wait 4 me in sch i finish ard 5..                      1      1  ham    1\n",
              "… and don‘t worry we‘ll have finished by march ...       1      1  ham    1\n",
              "… we r stayin here an extra week, back next wed...       1      1  ham    1\n",
              "\n",
              "[5169 rows x 4 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_spam.groupby('label').describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Iw_PT2iv3jWa"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'bel' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mbel\u001b[49m\n",
            "\u001b[31mNameError\u001b[39m: name 'bel' is not defined"
          ]
        }
      ],
      "source": [
        "bel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "collapsed": true,
        "id": "t4HSLJfWjE5Z"
      },
      "outputs": [],
      "source": [
        "# Verify length of the messages and also add it also as a new column (feature)\n",
        "df_spam['length'] =df_spam['label'].apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wyPj0LzNjE5a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  comment                                              label  length\n",
              "0     ham  Go until jurong point, crazy.. Available only ...     111\n",
              "1     ham                      Ok lar... Joking wif u oni...      29\n",
              "2    spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
              "3     ham  U dun say so early hor... U c already then say...      49\n",
              "4     ham  Nah I don't think he goes to usf, he lives aro...      61"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# view first 5 messages with length\n",
        "df_spam.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "t4aSzjR6jE5c"
      },
      "outputs": [],
      "source": [
        "# define a function to get rid of stopwords present in the messages\n",
        "def message_text_process(mess):\n",
        "    # Check characters to see if there are punctuations\n",
        "    no_punctuation = [char for char in mess if char not in string.punctuation]\n",
        "    # now form the sentence.\n",
        "    no_punctuation = ''.join(no_punctuation)\n",
        "    # Now eliminate any stopwords\n",
        "    return [word for word in no_punctuation.split() if word.lower() not in stopwords.words('english')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "Y4-NnGQnjE5b"
      },
      "outputs": [],
      "source": [
        "# start text processing with vectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eroik0Duu9q"
      },
      "source": [
        "**Bag Of Words**\n",
        "\n",
        "Bag of words is a simplistic model which gives information about the contents of a corpus in terms of number of occurrences of words.\n",
        "\n",
        "It ignores the grammar and context of the documents and is a mapping of words to their counts in the corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XSwpuLubuuUQ"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'CountVectorizer' object has no attribute 'get_feature_names'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m count_vectorizer = CountVectorizer()\n\u001b[32m      9\u001b[39m bag_of_words = count_vectorizer.fit_transform(content.splitlines())\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m pd.DataFrame(bag_of_words.toarray(), columns = \u001b[43mcount_vectorizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_feature_names\u001b[49m())\n",
            "\u001b[31mAttributeError\u001b[39m: 'CountVectorizer' object has no attribute 'get_feature_names'"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "content = \"\"\"Cake is a form of sweet food made from flour, sugar, and other ingredients, that is usually baked.\n",
        "In their oldest forms, cakes were modifications of bread, but cakes now cover a wide range of preparations that can be simple or elaborate, and that share features with other desserts such as pastries, meringues, custards, and pies.\"\"\"\n",
        "\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "bag_of_words = count_vectorizer.fit_transform(content.splitlines())\n",
        "\n",
        "pd.DataFrame(bag_of_words.toarray(), columns = count_vectorizer.get_feature_names())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   and  as  baked  be  bread  but  cake  cakes  can  cover  ...  simple  such  \\\n",
            "0    1   0      1   0      0    0     1      0    0      0  ...       0     0   \n",
            "1    2   1      0   1      1    1     0      2    1      1  ...       1     1   \n",
            "\n",
            "   sugar  sweet  that  their  usually  were  wide  with  \n",
            "0      1      1     1      0        1     0     0     0  \n",
            "1      0      0     2      1        0     1     1     1  \n",
            "\n",
            "[2 rows x 45 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "content = \"\"\"Cake is a form of sweet food made from flour, sugar, and other ingredients, that is usually baked.\n",
        "In their oldest forms, cakes were modifications of bread, but cakes now cover a wide range of preparations that can be simple or elaborate, and that share features with other desserts such as pastries, meringues, custards, and pies.\"\"\"\n",
        "\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "# Split the text into separate lines for the vectorizer\n",
        "bag_of_words = count_vectorizer.fit_transform(content.splitlines())\n",
        "\n",
        "# ✅ Use get_feature_names_out() instead of get_feature_names()\n",
        "df = pd.DataFrame(bag_of_words.toarray(), columns=count_vectorizer.get_feature_names_out())\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iJCC-VKAjE5c"
      },
      "outputs": [],
      "source": [
        "# bag of words by applying the function and fit the data (comment) into it\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "bag_of_words = CountVectorizer(analyzer=message_text_process).fit(df_spam['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Fp--3eUxjE5d"
      },
      "outputs": [],
      "source": [
        "# apply transform method for the bag of words\n",
        "comment_bagofwords = bag_of_words.transform(df_spam['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovcLYs78vxEU"
      },
      "source": [
        "**TF-IDF is technique in Natural Language Processing for converting words in Vectors and with some semantic information and it gives weighted to uncommon words , used in various NLP applications**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "a2tBwM0njE5d"
      },
      "outputs": [],
      "source": [
        "# apply tfidf transformer and fit the bag of words into it (transformed version)\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_transformer = TfidfTransformer().fit(comment_bagofwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "68zuZX3FjE5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5572, 11425)\n"
          ]
        }
      ],
      "source": [
        "# print shape of the tfidf\n",
        "comment_tfidf = tfidf_transformer.transform(comment_bagofwords)\n",
        "print(comment_tfidf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CGPASeTQjE5e"
      },
      "outputs": [],
      "source": [
        "#choose naive Bayes model to detect the spam and fit the tfidf data into it\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "spam_detection_model = MultinomialNB().fit(comment_tfidf,df_spam['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tI9GlBdZjE5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "expected spam label: Nah I don't think he goes to usf, he lives around here though\n"
          ]
        }
      ],
      "source": [
        "# check model for the predicted  and expampected value say for comment# 1 and comment#5\n",
        "\n",
        "print('expected spam label:', df_spam.label[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": true,
        "id": "2lsncXrvjE5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicted spam label  Sorry, I'll call later\n"
          ]
        }
      ],
      "source": [
        "print('predicted spam label ', spam_detection_model.predict(comment_tfidf)[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mxyqPh3Fk_V"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (MyEnv)",
      "language": "python",
      "name": "myenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
